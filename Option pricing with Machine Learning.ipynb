{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41ade67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rober\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\rober\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n",
      "C:\\Users\\rober\\AppData\\Local\\Temp/ipykernel_33556/1374421021.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from plotnine import *\n",
    "from itertools import product\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a4a3124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_scholes_price(S, K, r, T, sigma):\n",
    "    \"\"\"Calculate Black Scholes option price.\"\"\"\n",
    "  \n",
    "    d1 = (np.log(S/K)+(r+sigma**2/2)*T)/(sigma*np.sqrt(T))\n",
    "    d2 = d1-sigma*np.sqrt(T)\n",
    "    price = S*norm.cdf(d1)-K*np.exp(-r*T)*norm.cdf(d2)\n",
    "    \n",
    "    return price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5cc0d7",
   "metadata": {},
   "source": [
    "Where ML comes handy: We illustrate the concept of ML by showing how ML methods learn the Black-Scholes equation after observing some different specifications and corresponding prices without us revealing the exact pricing equation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943eae5d",
   "metadata": {},
   "source": [
    " - Start with simulated data\n",
    " - Compute option prices for call options for a **grid** of different combinations of times to maturity (T), risk-free rates, volatilies (sigma), strike prices (K), and current stock prices (S). \n",
    " -  In the code below, we add an idiosyncratic error term to each observation such that the prices considered do not exactly reflect the values implied by the Black-Scholes equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fba1c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "np.random.seed(random_state) #to keep the analysis reproducible \n",
    "\n",
    "S = np.arange(40, 61) #numpy.arange returns evenly spaced values within a given interval. When not spec the interval is 1\n",
    "K = np.arange(20, 91) #inteval is specified as the third argument\n",
    "r = np.arange(0, 0.051, 0.01)\n",
    "T = np.arange(3/12, 2.01, 1/12)\n",
    "sigma = np.arange(0.1, 0.81, 0.1)\n",
    "\n",
    "option_prices = pd.DataFrame(\n",
    "  product(S, K, r, T, sigma), #is product a binomial coeff of combinations? #in dataframe\n",
    "  columns=[\"S\", \"K\", \"r\", \"T\", \"sigma\"]\n",
    ")\n",
    "\n",
    "option_prices[\"black_scholes\"] = black_scholes_price(\n",
    "  option_prices[\"S\"].values, \n",
    "  option_prices[\"K\"].values, \n",
    "  option_prices[\"r\"].values, \n",
    "  option_prices[\"T\"].values, \n",
    "  option_prices[\"sigma\"].values\n",
    ")\n",
    "\n",
    "option_prices = (option_prices\n",
    "  .assign(\n",
    "    observed_price=lambda x: (\n",
    "      x[\"black_scholes\"] + np.random.normal(scale=0.15) #random error\n",
    "    )\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "040d068f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>K</th>\n",
       "      <th>r</th>\n",
       "      <th>T</th>\n",
       "      <th>sigma</th>\n",
       "      <th>black_scholes</th>\n",
       "      <th>observed_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.074507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.074507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.000002</td>\n",
       "      <td>20.074509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20.000377</td>\n",
       "      <td>20.074884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20.005859</td>\n",
       "      <td>20.080367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574491</th>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>7.193144</td>\n",
       "      <td>7.267651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574492</th>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.528885</td>\n",
       "      <td>10.603392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574493</th>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>13.911119</td>\n",
       "      <td>13.985626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574494</th>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.7</td>\n",
       "      <td>17.267163</td>\n",
       "      <td>17.341670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574495</th>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>20.553149</td>\n",
       "      <td>20.627657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1574496 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          S   K     r     T  sigma  black_scholes  observed_price\n",
       "0        40  20  0.00  0.25    0.1      20.000000       20.074507\n",
       "1        40  20  0.00  0.25    0.2      20.000000       20.074507\n",
       "2        40  20  0.00  0.25    0.3      20.000002       20.074509\n",
       "3        40  20  0.00  0.25    0.4      20.000377       20.074884\n",
       "4        40  20  0.00  0.25    0.5      20.005859       20.080367\n",
       "...      ..  ..   ...   ...    ...            ...             ...\n",
       "1574491  60  90  0.05  2.00    0.4       7.193144        7.267651\n",
       "1574492  60  90  0.05  2.00    0.5      10.528885       10.603392\n",
       "1574493  60  90  0.05  2.00    0.6      13.911119       13.985626\n",
       "1574494  60  90  0.05  2.00    0.7      17.267163       17.341670\n",
       "1574495  60  90  0.05  2.00    0.8      20.553149       20.627657\n",
       "\n",
       "[1574496 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "option_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0166e98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(\n",
    "  option_prices, \n",
    "  test_size=0.01, random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce6899dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess the data\n",
    "preprocessor = ColumnTransformer(\n",
    "  transformers=[(\n",
    "    \"normalize_predictors\", \n",
    "     StandardScaler(),\n",
    "     [\"S\", \"K\", \"r\", \"T\", \"sigma\"]\n",
    "  )],\n",
    "  remainder=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c68c0b",
   "metadata": {},
   "source": [
    "## Single layer networks and random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c849618e",
   "metadata": {},
   "source": [
    "How to fit a neural network to the data. The function MLPRegressor() from the package scikit-learn provides the functionality to initialize a single layer, feed-forward neural network. The specification below defines a single layer feed-forward neural network with ten hidden units. We set the number of training iterations to max_iter=1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e86b4478",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 1000\n",
    "\n",
    "nnet_model = MLPRegressor(\n",
    "  hidden_layer_sizes=10, \n",
    "  max_iter=max_iter, \n",
    "  random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae978f7f",
   "metadata": {},
   "source": [
    "We can follow the straightforward workflow as in the chapter before: define a workflow, equip it with the recipe, and specify the associated model. Finally, fit the model with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51c0533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet_pipeline = Pipeline([\n",
    "  (\"preprocessor\", preprocessor),\n",
    "  (\"regressor\", nnet_model)\n",
    "])\n",
    "\n",
    "nnet_fit = nnet_pipeline.fit(\n",
    "  train_data.drop(columns=[\"observed_price\"]), \n",
    "  train_data.get(\"observed_price\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d738c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "  n_estimators=50, \n",
    "  min_samples_leaf=2000, \n",
    "  random_state=random_state\n",
    ")\n",
    "\n",
    "rf_pipeline = Pipeline([\n",
    "  (\"preprocessor\", preprocessor),\n",
    "  (\"regressor\", rf_model)\n",
    "])\n",
    "\n",
    "rf_fit = rf_pipeline.fit(\n",
    "  train_data.drop(columns=[\"observed_price\"]), \n",
    "  train_data.get(\"observed_price\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1f2e04",
   "metadata": {},
   "source": [
    "## Deep neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6711e337",
   "metadata": {},
   "source": [
    "A deep neural network is a neural network with multiple layers between the input and output layers. By chaining multiple layers together, more complex structures can be represented with fewer parameters than simple shallow (one-layer) networks as the one implemented above. \n",
    "The following code chunk implemenets a deep neural network with three hidden layers of size ten each and logistic activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bec3d82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rober\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n"
     ]
    }
   ],
   "source": [
    "deepnnet_model = MLPRegressor(\n",
    "  hidden_layer_sizes=(10, 10, 10),\n",
    "  activation=\"logistic\", \n",
    "  solver=\"lbfgs\",\n",
    "  max_iter=max_iter, \n",
    "  random_state=random_state\n",
    ")\n",
    "                              \n",
    "deepnnet_pipeline = Pipeline([\n",
    "  (\"preprocessor\", preprocessor),\n",
    "  (\"regressor\", deepnnet_model)\n",
    "])\n",
    "\n",
    "deepnnet_fit = deepnnet_pipeline.fit(\n",
    "  train_data.drop(columns=[\"observed_price\"]),\n",
    "  train_data.get(\"observed_price\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426b6fbd",
   "metadata": {},
   "source": [
    "## Universal approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dceeb73",
   "metadata": {},
   "source": [
    "Before we evaluate the results, we implement one more model. In principle, any non-linear function can also be approximated by a linear model containing the input variables’ polynomial expansions.\n",
    "To illustrate this, we include polynomials up to the fifth degree of each predictor and then add all possible pairwise interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b828eda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_pipeline = Pipeline([\n",
    "  (\"polynomial\", PolynomialFeatures(degree=5, \n",
    "                                    interaction_only=False, \n",
    "                                    include_bias=True)),\n",
    "  (\"scaler\", StandardScaler()),\n",
    "  (\"regressor\", Lasso(alpha=0.01))\n",
    "])\n",
    "\n",
    "lm_fit = lm_pipeline.fit(\n",
    "  train_data.get([\"S\", \"K\", \"r\", \"T\", \"sigma\"]),\n",
    "  train_data.get(\"observed_price\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4577964",
   "metadata": {},
   "source": [
    "Collect all predictions to compare the out-of-sample prediction error evaluated on ten thousand new data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed33462",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_data.get([\"S\", \"K\", \"r\", \"T\", \"sigma\"])\n",
    "test_y = test_data.get(\"observed_price\")\n",
    "\n",
    "predictive_performance = (pd.concat(\n",
    "    [test_data.reset_index(drop=True), \n",
    "     pd.DataFrame({\"Random forest\": rf_fit.predict(test_X),\n",
    "                   \"Single layer\": nnet_fit.predict(test_X),\n",
    "                   \"Deep NN\": deepnnet_fit.predict(test_X),\n",
    "                   \"Lasso\": lm_fit.predict(test_X)})\n",
    "    ], axis=1)\n",
    "  .melt(\n",
    "    id_vars=[\"S\", \"K\", \"r\", \"T\", \"sigma\",\n",
    "             \"black_scholes\", \"observed_price\"],\n",
    "    var_name=\"Model\",\n",
    "    value_name=\"Predicted\"\n",
    "  )\n",
    "  .assign(\n",
    "    moneyness=lambda x: x[\"S\"]-x[\"K\"],\n",
    "    pricing_error=lambda x: np.abs(x[\"Predicted\"]-x[\"black_scholes\"])\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca77160",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_performance_plot = (\n",
    "  ggplot(predictive_performance, \n",
    "         aes(x=\"moneyness\", y=\"pricing_error\")) +\n",
    "  geom_point(alpha=0.05) +\n",
    "  facet_wrap(\"Model\") + \n",
    "  labs(x=\"Moneyness (S - K)\", y=\"Absolut prediction error (USD)\",\n",
    "       title=\"Prediction errors of call options for different models\") +\n",
    "  theme(legend_position=\"\")\n",
    ")\n",
    "predictive_performance_plot.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
